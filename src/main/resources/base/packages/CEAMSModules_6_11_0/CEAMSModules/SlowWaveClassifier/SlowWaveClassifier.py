"""
@ CIUSSS DU NORD-DE-L'ILE-DE-MONTREAL â€“ 2023
See the file LICENCE for full license details.
"""
"""
    SlowWaveClassifier
    This plugin classifies slow wave events based on a gaussian mixture. It selects
    the best gaussian fit based on Akaike information criterion (AIC) and passes
    those informations to a KMean function which then seperates each detected 
    slow wave into n categories, where n is determined by the best gaussian fit.
    Values of n range between 1 and 5. Categorized slow waves are then saved in cache
    along with data for each slow wave criterion.

    It requires start_time, name and trans_freq_Hz.  The category is computed and added to the event dataframe.

    Parameters
    -----------      
    sw_char_files : list of strings
        List of filename to load events_details.
        events_details are pandas DataFrames (columns=['group', 'name', 'cycle', 'stage', 
        'start_sec', 'duration_sec', 'pkpk_amp_uV', 'freq_Hz', 'neg_amp_uV', 'neg_sec', 'pos_sec',|
         'slope_0_min', 'slope_min_max', 'slope_max_0', 'trans_freq_Hz', 'channels'])
    sw_cohort_file : string
        File containing the slow wave cohort information generated by the slow wave detector.
    sw_stages_files : list of strings
        List of filename to load sleep stages.
    automatic_classification    : boolean
        The user specifies whether they want to specify the number of categories or not.
        Usually selected (True) for a group classification. Unselect (False)
        when the user inputs an individual of the same group in a second round
        of classification to have more details. 
    num_categories  : int
        The number of categories of sleep slow waves to analyse.
    num_divisions  : int
            The number of divisions in the recording length to divide the night into.
    report_constants: dict
            Constants used in the report (N_HOURS, N_CYCLES)
    output_dir : string
        The directory where the results are saved.

    Returns
    -----------  
    categorized_data  : pandas DataFrame
        DataFrame events (columns=['category','n_t','PaP','Neg', 'tNe', 'tPo', 'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz'])
        containing data analysis of parameters for each slow wave category found
    data_details : Pandas DataFrame
        DataFrame containing a column for each category of sleep slow waves
        found. The indexes describe what the data is about.
    distr_time : Pandas DataFrame
        DataFrame events showing the number of ssw in each category accros each
        the entire night.
    distr_cycle : Pandas DataFrame
        DataFrame events showing the mean value for each quarter of the night
    distr_quarter : Pandas DataFrame
        DataFrame events showing the number of ssw in each category accros each
        cycle.


    @author: CloÃ© Dutil (cloe.dutil.1@ens.etsmtl.ca)

    Log : 
        2022-0X-XX : First release, CloÃ© Dutil
"""
import matplotlib.pyplot as plt
import math
import numpy as np
import os
import pandas as pd
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans

from flowpipe import SciNode, InputPlug, OutputPlug
from commons.NodeInputException import NodeInputException
from commons.NodeRuntimeException import NodeRuntimeException

from CEAMSModules.PSGReader import commons
from CEAMSModules.SlowWaveClassifier.SlowWaveClassifierResultsView import SlowWaveClassifierResultsView
from CEAMSModules.SlowWaveClassifier.SlowWaveClassifierDoc import write_doc_file
from CEAMSModules.SlowWaveClassifier.SlowWaveClassifierDoc import _get_doc

DEBUG = False

class SlowWaveClassifier(SciNode):
    """
    This plugin classifies slow wave events based on a gaussian mixture. It selects
    the best gaussian fit based on Akaike information criterion (AIC) and passes
    those informations to a KMean function which then seperates each detected 
    slow wave into n categories, where n is determined by the best gaussian fit.
    Values of n range between 1 and 4. Categorized slow waves are then saved in cache
    along with data for each slow wave criterion.

    Parameters
    -----------      
        sw_char_files : list of strings
            List of filename to load events_details.
            events_details are pandas DataFrames (columns=['group', 'name', 'cycle', 'stage', 
            'start_sec', 'duration_sec', 'pkpk_amp_uV', 'freq_Hz', 'neg_amp_uV', 'neg_sec', 'pos_sec',|
            'slope_0_min', 'slope_min_max', 'slope_max_0', 'trans_freq_Hz', 'channels'])
        sw_cohort_file : string
            File containing the slow wave cohort information generated by the slow wave detector.
        sw_stages_files : list of strings
            List of filename to load sleep stages.
        automatic_classification    : boolean
            The user specifies whether they want to specify the number of categories or not.
            Usually selected (True) for a group classification. Unselect (False)
            when the user inputs an individual of the same group in a second round
            of classification to have more details. 
        num_categories  : int
            The number of categories of sleep slow waves to analyse.
        num_divisions  : int
            The number of divisions in the recording length to divide the night into.
        report_constants: dict
                Constants used in the report (N_HOURS, N_CYCLES)
        output_dir : string
            The directory where the results are saved.

    Returns
    -----------  
        categorized_data  : pandas DataFrame
            DataFrame events (columns=['category','n_t','PaP','Neg', 'tNe', 'tPo', 'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz'])
            containing data analysis of parameters for each slow wave category found
        data_details : Pandas DataFrame
            DataFrame containing a column for each category of sleep slow waves
            found. The indexes describe what the data is about.
        distr_time : Pandas DataFrame
            DataFrame events showing the number of ssw in each category accros each
            the entire night.
        distr_cycle : Pandas DataFrame
            DataFrame events showing the mean value for each quarter of the night
        distr_quarter : Pandas DataFrame
            DataFrame events showing the number of ssw in each category accros each
            cycle.
    """

    def __init__(self, **kwargs):
        """ Initialize module SlowWaveClassifier """
        super().__init__(**kwargs)
        if DEBUG: print('SleepReport.__init__')

        # Input plugs
        InputPlug('sw_char_files', self)
        InputPlug('sw_cohort_file', self)
        InputPlug('sw_stages_files', self)
        InputPlug('automatic_classification', self)
        InputPlug('num_categories', self)
        InputPlug('num_divisions', self)
        InputPlug('report_constants', self)
        InputPlug('output_dir', self)

        # Output plugs
        OutputPlug('categorized_data',self)
        OutputPlug('data_details',self)
        OutputPlug('distr_time',self)
        OutputPlug('distr_cycle',self)
        OutputPlug('distr_quarter',self)

        # A master module allows the process to be reexcuted multiple time.
        # For exemple, this is useful when the process must be repeated over multiple
        # files. When the master module is done, ie when all the files were process, 
        # The compute function must set self.is_done = True
        # There can only be 1 master module per process.
        self._is_master = False 
        self.slow_wave_df = pd.DataFrame()
        self.slow_wave_list = []
        self.columns_to_avg = ['duration_sec', 'pkpk_amp_uV', 'freq_Hz', 'neg_amp_uV', 'neg_sec', 'pos_sec','slope_0_min', 'slope_min_max', 'slope_max_0', 'trans_freq_Hz']

    def compute(self, sw_char_files, sw_cohort_file, sw_stages_files, automatic_classification,\
        num_categories, num_divisions, report_constants, output_dir):
        """
        This function classifies slow wave events with KMeans, based on a gaussian
        mixture selected with Akaike information criterion (AIC). Gaussian distribution
        of 1 to 4 are tested. Analysis data is provided by pandas.

        Parameters
        --------      
            sw_char_files : list of strings
                List of filename to load events_details.
                events_details are pandas DataFrames (columns=['group', 'name', 'cycle', 'stage', 
                'start_sec', 'duration_sec', 'pkpk_amp_uV', 'freq_Hz', 'neg_amp_uV', 'neg_sec', 'pos_sec',|
                'slope_0_min', 'slope_min_max', 'slope_max_0', 'trans_freq_Hz', 'channels'])
            sw_cohort_file : string
                File containing the slow wave cohort information generated by the slow wave detector.
            sw_stages_files : list of strings
                List of filename to load sleep stages.
            automatic_classification    : boolean
                The user specifies whether they want to specify the number of categories or not.
                Usually selected (True) for a group classification. Unselect (False)
                when the user inputs an individual of the same group in a second round
                of classification to have more details. 
            num_categories  : int
                The number of categories of sleep slow waves to analyse.
            num_divisions  : int
                The number of divisions in the recording length to divide the night into.
            report_constants: dict
                Constants used in the report (N_HOURS, N_CYCLES)
            output_dir : string
                The directory where the results are saved.

        Returns
        -----------  
            categorized_data  : pandas DataFrame
                DataFrame events (columns=['category','n_t','PaP','Neg', 'tNe', 'tPo', 'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz'])
                containing data analysis of parameters for each slow wave category found
            data_details : Pandas DataFrame
                DataFrame containing a column for each category of sleep slow waves
                found. The indexes describe what the data is about.
            distr_time : Pandas DataFrame
                DataFrame events showing the number of ssw in each category accros each
                the entire night.
            distr_cycle : Pandas DataFrame
                DataFrame events showing the mean value for each quarter of the night
            distr_quarter : Pandas DataFrame
                DataFrame events showing the number of ssw in each category accros each
                cycle.
        """
        if isinstance(num_divisions, str):
            num_divisions = int(num_divisions)

        if isinstance(sw_char_files, str):
            sw_char_files = eval(sw_char_files)

        if not isinstance(sw_char_files, list):
            raise NodeInputException(self.identifier, "sw_char_files", \
                f"SlowWaveClassifier input of wrong type. Expected: list received: {type(sw_char_files)}")

        if isinstance(sw_stages_files, str):
            sw_stages_files = eval(sw_stages_files)

        if not isinstance(sw_stages_files, list):
            raise NodeInputException(self.identifier, "sw_stages_files", \
                f"SlowWaveClassifier input of wrong type. Expected: list received: {type(sw_stages_files)}")

        if isinstance(report_constants,str) and report_constants == '':
            raise NodeInputException(self.identifier, "report_constants", \
                "SlowWaveClassifier report_constants parameter must be set.")
        elif isinstance(report_constants,str):
            report_constants = eval(report_constants)
        if isinstance(report_constants,dict) == False:
            raise NodeInputException(self.identifier, "report_constants",\
                "SlowWaveClassifier report_constants expected type is dict and received type is " + str(type(report_constants)))

        self.N_CYCLES = int(float(report_constants['N_CYCLES']))

        # Initialize variables
        self.MAX_ITERATIONS = 200
        aic_results = []
        dists = []

        if eval(automatic_classification):   
            self.MIN_DISTRIBUTIONS = 1
            self.MAX_DISTRIBUTIONS = 4
        else:
            self.MIN_DISTRIBUTIONS = int(num_categories)
            self.MAX_DISTRIBUTIONS = int(num_categories)
        
        #-----------------------------------------
        # Read slow wave characteristics from each file in sw_char_files
        #-----------------------------------------
            # self.slow_wave_df and self.slow_wave_list are updated
            # self.slow_wave_df is a concatenation of all slow wave characteristics
            # self.slow_wave_list is a list of all slow wave characteristics (one item per filename)
        self.read_slow_wave_characteristics(sw_char_files)

        # Read sw_cohort_file
        # Read the csv file and convert the content into a Data Frame
        sw_cohort_df = pd.read_csv(sw_cohort_file, delimiter='\t', header=0, encoding='utf-8')        

        # Get data for gaussian mixture ready
        tfr_data = self.slow_wave_df['trans_freq_Hz'].tolist()
        tfr_data_2D = np.array(tfr_data)
        tfr_data_2D = tfr_data_2D.reshape(-1,1)   # Gaussian Mixture requires 2D array

        #-----------------------------------------
        # Computation for classifying data with Gaussian Mixture ()
        #-----------------------------------------
        # Create and fit model : a few number of clusters are tried, then it is possible to get a warning of nonconvergence
        aic_results, dists = self.gaussian_mixture(tfr_data_2D) 
        # Select the best model based on AIC (could be the model that did not converge)
        index_best_dist, n_dist = self.find_best_distribution(aic_results) 
        # Classify data with the best model, get the sw category of each sw event
        km = self.kmeans_classification(dists, tfr_data_2D, index_best_dist, n_dist) 
        # Attribute the category to each sw event (self.slow_wave_df and self.slow_wave_list are updated)
        self.get_classification_data(km)

        #-----------------------------------------
        # Output slow wave characteristics files (one file per recording)
        #-----------------------------------------
        self.save_slow_wave_characteristics(sw_char_files, output_dir)

        #-----------------------------------------
        # Output cohort slow wave characteristics. One file for the whole cohort
        #-----------------------------------------
        # Save the picture of the frequency transition distribution and the AIC
        self.save_transition_frequency_distribution(tfr_data, dists[index_best_dist], aic_results, output_dir, n_dist)

        # Average slow wave characteristics per category
        sw_char_cat_total, chan_list_recor = self.average_slow_waves_char_per_category(sw_char_files, n_dist, sw_cohort_df)

        # Average slow wave characteristics per category per sleep cycle
        sw_char_cat_cycle = self.average_slow_waves_char_per_cycle(sw_char_files, n_dist, sw_cohort_df, chan_list_recor)
        sw_char_cohort_df = pd.concat([sw_char_cat_total, sw_char_cat_cycle], axis=1)

        # Average slow wave characteristics per category per division of the night
        sw_char_cat_division = self.average_slow_waves_char_per_division(\
            sw_char_files, sw_stages_files, n_dist, sw_cohort_df, num_divisions, chan_list_recor)
        sw_char_cohort_df = pd.concat([sw_char_cohort_df, sw_char_cat_division], axis=1)

        # Organize data to write the cohort slow wave report with categories
        # Construction of the pandas dataframe that will be used to create the TSV file
        # Order columns as the doc file
        out_columns = list(_get_doc(self.N_CYCLES, num_divisions, n_dist).keys())
        sw_char_cohort_df = sw_char_cohort_df[out_columns]
        cohort_filename = output_dir + "sw_cohort_details_per_categories.tsv"
        file_name, file_extension = os.path.splitext(cohort_filename)
        doc_filepath = file_name+"_info"+file_extension
        try : 
            sw_char_cohort_df.to_csv(path_or_buf=cohort_filename, sep='\t', \
                index=False, index_label='False', mode='w', header=True, encoding="utf_8")

            # Write the documentation file
            if not os.path.exists(doc_filepath):
                write_doc_file(doc_filepath, self.N_CYCLES, num_divisions, n_dist)
                # Log message for the Logs tab
                self._log_manager.log(self.identifier, f"The file {doc_filepath} has been created.")

        except :
            error_message = f"Snooz can not write in the file {cohort_filename} or {doc_filepath}."+\
                f" Check if the drive is accessible and ensure the file is not already open."
            raise NodeRuntimeException(self.identifier, "SlowWavesDetails", error_message)         

        # # Computation to visualise data
        # time_df = self.get_distribution_by_time_data(n_dist, self.slow_wave_df, signals_time)
        # cycle_df = self.get_distribution_by_cycle_data(n_dist, self.slow_wave_df, sleep_stage_events)
        # quarter_night_df = self.get_distribution_night_quarter_data(n_dist, self.slow_wave_df, \
        #                     signals_time, sleep_stage_events, events)

        # Send data to view through cache
        cache = {}
        cache['gm_data'] = dists[index_best_dist]
        cache['histogram_data'] = tfr_data
        cache['aic_data'] = aic_results
        cache['n_categories'] = n_dist
        # cache['has_one_signal_only'] = self.has_one_signal_only
        # cache['categorized_data'] = events_classified
        # cache['data_details'] = classification_data
        # cache['distr_time'] = time_df
        # cache['distr_cycle'] = cycle_df
        # cache['distr_quarter'] = quarter_night_df
        # cache['id'] = list_name[0]
        # self._cache_manager.write_mem_cache(self.identifier, cache)
        
        # return {
        #     'categorized_data': events_classified,
        #     'data_details': classification_data,
        #     'distr_time': time_df,
        #     'distr_cycle': cycle_df,
        #     'distr_quarter': quarter_night_df
        # }

        return {
            'categorized_data': '',
            'data_details': '',
            'distr_time': '',
            'distr_cycle': '',
            'distr_quarter': ''
        }


    # Read the list of sw_char_files and init self.slow_wave_df and self.slow_wave_list
    def read_slow_wave_characteristics(self, sw_char_files):
        for filename in sw_char_files:
            # Read the csv file and convert the content into a Data Frame
            slow_wave_df = pd.read_csv(filename, delimiter='\t', header=0, encoding='utf-8')
            slow_wave_df.reset_index(drop=True, inplace=True)
            self.slow_wave_list.append(slow_wave_df)
            self.slow_wave_df = pd.concat([self.slow_wave_df, slow_wave_df])
            self.slow_wave_df.reset_index(drop=True, inplace=True)


    # Write the information in self.slow_wave_list to each file of the sw_char_files list
    def save_slow_wave_characteristics(self, sw_char_files, output_dir):
        for i_recor, filename in enumerate(sw_char_files):
            # Split the file name and path from filename string
            path, file_name = os.path.split(filename)
            # Write the dataframe into a csv file 
            try:
                self.slow_wave_list[i_recor].to_csv(output_dir+file_name, sep='\t', index=False, header=True, mode='w')
            except :
                error_message = f"Snooz can not write in the file {filename}."+\
                    f" Check if the drive is accessible and ensure the file is not already open."
                raise NodeRuntimeException(self.identifier, "SlowWaveClassifier", error_message)  


    def gaussian_mixture(self, tfr_data):
        """
        Finds the AIC value for gaussian mixture distributions between min and 
        max distributions value

        Parameters
        --------      
        tfr_data   : list, transition frequency of each detected slow wave
        aic_results : list, aic value (float) for each distribution
        dists   :   list, GaussianMixture value
        
        Returns
        -----------
        aic_results : list, aic value for each distribution computed
        dists   : list, GaussianMixture of each distribution computed
        """

        aic_results = []
        dists = []

        self._log_manager.log(self.identifier,"\nAIC values:")
        for i in range(self.MIN_DISTRIBUTIONS, self.MAX_DISTRIBUTIONS + 1):
            gm = GaussianMixture(n_components=i, max_iter=self.MAX_ITERATIONS, tol=1e-6, init_params='k-means++').fit(tfr_data)
            dists.append(gm)
            aic = gm.aic(tfr_data)
            aic_results.append(aic)
            self._log_manager.log(self.identifier, str(aic) + " for " + str(i) + " distributions")
        return aic_results, dists


    def find_best_distribution(self, aic_results):
        """
        Finds the best distribution with AIC

        Parameters
        --------      
        aic_results : list, aic value (float) for each distribution

        Returns
        -----------  
        index_best_dist : int, index position of the best gaussian mixture model
        n_dist  : int, number of distributions detected in data
        """

        index_best_dist = np.argmin(aic_results)
        n_dist = index_best_dist + self.MIN_DISTRIBUTIONS
        self._log_manager.log(self.identifier, "AIC CONVERGING TOWARDS " 
                                + str(n_dist) + " DISTRIBUTIONS")
        return index_best_dist, n_dist


    def kmeans_classification(self, dists, tfr_data_2D, index_best_dist, n_dist):
        """
        Classify slow waves into n_dist categories using the peaks found with
        the gaussian mixture
        
        Parameters
        --------      
        dists   :   list, GaussianMixture value
        tfr_data_2D   : array, 2D array of transition frequency of each detected slow wave
        index_best_dist : int, index position of the best gaussian mixture model
        n_dist  : int, number of distributions detected in data
        
        Returns
        -----------  
        km : KMeans object
        """
        
        gm_peaks = dists[index_best_dist].means_.flatten()
        gm_peaks = np.array(gm_peaks)
        gm_peaks = gm_peaks.reshape(-1, 1)
        km = KMeans(n_dist, init=gm_peaks, n_init=1).fit(tfr_data_2D)
        return km
    
    
    def get_classification_data(self, km):
        """
        Takes the event's data and puts it into two DataFrames: one containing the category
        in which each detection is classified and the second containing details
        on each category.

        Parameters
        --------      
            km          : KMeans object
                the kmeans object that contains the category of each slow wave event
        Returns
        -----------  
            self.slow_wave_df and self.slow_wave_list are updated with the category of the slow wave
        """

        # Add the category to each event in the dataframe concatenated
        self.slow_wave_df['category'] = km.labels_+1
        self.slow_wave_df['category'].astype(int)

        # Add the category to each event in the list of dataframes
        i_sw = 0
        for i_recor, recor in enumerate(self.slow_wave_list):
            for i, event in recor.iterrows():
                recor.loc[i,['category']] = km.labels_[i_sw]+1
                i_sw += 1
            self.slow_wave_list[i_recor]['category'] = recor['category'].astype(int)


    def get_distribution_by_time_data(self, n_categories, events_details, signals_time):
        """
        Returns a dataframe containing information about the sleep slow wave 
        distribution for each cycle.

        Parameters
        -----------
        n_categories  : int
            The number of categories of sleep slow waves to analyse. 
        events_details     : Pandas DataFrame
            DataFrame events (columns=['start_sec', 'duration_sec', 'n_t','pkpk_amp_uV','neg_amp_uV', 'neg_sec', 'pos_sec',|
            'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz', 'slope_0_min', 'slope_min_max', 'slope_min_0', 'channels','name'])
            containing data of each detected slow wave for further analysis
        signals_time : Pandas DataFrame
            DataFrame events (columns=['start_time','end_time','channels','name'])
            containing information on the start_time, end_time and name of each signal.
            Used to retrieve which signal came from which file.

        Returns
        -----------
        time_df : Pandas DataFrame
            DataFrame events showing the number of ssw in each category accros each
            the entire night.
        """

        if self.has_one_signal_only:
            distr_columns = [f'SSW category #{i + 1}' for i in range(n_categories)]
            distr_columns.insert(0, 'Total')
            distr_index = []
            distr_data = []
            time_jump = 300      # in seconds, (5 mins)
            values = {i: [] for i in range(n_categories)}
            values['total'] = []

            for _, row in signals_time.iterrows():
                for s in range(math.floor(row['start_time']), math.ceil(row['end_time']), time_jump):
                    result = events_details[(events_details['start_sec'] >= s) & (events_details['start_sec'] < s + time_jump)]["category"]

                    cat_count = result.value_counts()
                    for i in range(n_categories):
                        if i not in cat_count:
                            cat_count[i] = 0
                        values[i].append(cat_count[i])
                    
                    total = len(result)
                    cat_count = cat_count.sort_index().to_list()
                    cat_count.insert(0, total)
                    values['total'].append(total)

                    distr_index.append('{:0.2f} mins'.format((s + time_jump) / 60))   # Show data in minutes
                    distr_data.append(cat_count)
            
            time_df = pd.DataFrame(data=distr_data, columns=distr_columns, index=distr_index)
        
        else:
            time_df = None

        return time_df

    
    def get_distribution_by_cycle_data(self, n_categories, events_details, sleep_stage_events):
        """
        Returns a dataframe containing information about the sleep slow wave 
        distribution for each cycle.

        Parameters
        -----------
        n_categories  : int
            The number of categories of sleep slow waves to analyse. 
        events_details     : Pandas DataFrame
            DataFrame events (columns=['start_sec', 'duration_sec', 'n_t','pkpk_amp_uV','neg_amp_uV', 'neg_sec', 'pos_sec',|
            'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz', 'slope_0_min', 'slope_min_max', 'slope_min_0', 'channels','name'])
            containing data of each detected slow wave for further analysis
        sleep_stage_events   : pandas DataFrame
            List of events from specific stages.

        Returns
        -----------
        cycle_df : Pandas DataFrame
            DataFrame events showing the number of ssw in each category accros each
            cycle.
        """

        # Show sleep cycles only if there's data for it (if it's a Dataframe)
        if self.has_one_signal_only \
            and not(isinstance(sleep_stage_events, str) and sleep_stage_events == ''):
            
            # Variables
            distr_columns = [f'SSW category #{i + 1}' for i in range(n_categories)]
            distr_columns.insert(0, 'Total')
            distr_index = []
            distr_data = []
            values = {i: [] for i in range(n_categories)}
            values['total'] = []

            # Keep all cycle events
            cycles = sleep_stage_events[sleep_stage_events['group'] == commons.sleep_cycle_group]

            if len(cycles) > 0:
                """
                A cycle is defined by their start time and the start time of the next cycle
                Ex: We haves cycle events at 1:35:00, 1:57:55 and 2:21:46
                This forms two cycles: one starting at 1:35:00 and ending at 1:57:55
                and another one starting at 1:57:55 and ending at 2:21:46
                """
                
                start_cycle = cycles.iloc[0]

                for i in range(1, len(cycles)):
                    result = events_details[(events_details['start_sec'] >= start_cycle['start_sec']) \
                                            & (events_details['start_sec'] < cycles.iloc[i]['start_sec'])]["category"]
                    
                    cat_count = result.value_counts().sort_index().to_list()
                    for n in range(len(cat_count)):
                        values[n].append(cat_count[n])
                    
                    total = len(result)
                    cat_count.insert(0, total)
                    values['total'].append(total)
                    
                    distr_index.append(f'Cycle #{i}')
                    distr_data.append(cat_count)
                    start_cycle = cycles.iloc[i]
                
                cycle_df = pd.DataFrame(data=distr_data, columns=distr_columns, index=distr_index)

            else:
                cycle_df = None

        else:
            cycle_df = None

        return cycle_df

    
    def get_distribution_night_quarter_data(self, n_categories, events_details, \
                                            signals_time, sleep_stage_events, \
                                            events):
        """
        Returns a dataframe containing information about the sleep slow wave 
        distribution for each quarter of the night.

        Parameters
        -----------
        n_categories  : int
            The number of categories of sleep slow waves to analyse. 
        events_details     : Pandas DataFrame
            DataFrame events (columns=['start_sec', 'duration_sec', 'n_t','pkpk_amp_uV','neg_amp_uV', 'neg_sec', 'pos_sec',|
            'Pap_raw', 'Neg_raw', 'mfr', 'trans_freq_Hz', 'slope_0_min', 'slope_min_max', 'slope_min_0', 'channels','name'])
            containing data of each detected slow wave for further analysis
        signals_time : Pandas DataFrame
            DataFrame events (columns=['start_time','end_time','channels','name'])
            containing information on the start_time, end_time and name of each signal.
            Used to retrieve which signal came from which file.
        sleep_stage_events   : pandas DataFrame
            List of events from specific stages.
        events  : Pandas DataFrame
            DataFrame events (columns=['group','name','start_sec','duration_sec','channels']) 
            containing a slow wave event

        Returns
        -----------
        quarter_night_df : Pandas DataFrame
            DataFrame events showing the mean value for each quarter of the night
        """

        # Variables
        NUM_PARTS = 4
        distr_columns = [f'Mean value SSW category #{i + 1}' for i in range(n_categories)]
        distr_index = [f'{i + 1}/{NUM_PARTS} part of the night (N2 & N3 stages)' for i in range(NUM_PARTS)]
        distr_data = {i : 0 for i in range(NUM_PARTS)}
        table_data = {i : [[] for _ in range(n_categories)] for i in range(NUM_PARTS)}
        
        # Set up data format
        quarters = self._set_data_sleep_quarter_distribution(NUM_PARTS, signals_time, \
                                                            sleep_stage_events, events)
        quarter_night_df = None
        
        # Collect and show data
        if len(quarters) > 0:
            for i in range(len(quarters)):
                for sleep_part in range(NUM_PARTS):
                    start_time = quarters[i][sleep_part].iloc[0]['start_sec']
                    s_end = quarters[i][sleep_part].iloc[len(quarters[i][sleep_part]) - 1]
                    end_time = s_end['start_sec'] + s_end['duration_sec']
                    names = events["name"].unique().tolist()
                    
                    result = events_details[(events_details['start_sec'] >= start_time) \
                                            & (events_details['start_sec'] < end_time)
                                            & (events_details['name'] == names[i])]["category"]

                    # Compile values for each category
                    cat_count = result.value_counts().sort_index().to_list()
                    for n in range(len(cat_count)):
                        table_data[sleep_part][n].append(cat_count[n])
                

            # Compute mean value            
            for i in range(NUM_PARTS):
                l = []
                lt = []
                for j in range(n_categories):
                    mean = np.mean(table_data[i][j])
                    s = "{:0.2f} +- {:0.2f}".format(mean, np.std(table_data[i][j]))
                    l.append(s)
                    lt.append(mean)
                table_data[i] = l
                distr_data[i] = lt
            
            table_data = table_data.values()
            quarter_night_df = pd.DataFrame(data=table_data, columns=distr_columns, index=distr_index, dtype=str)

        return quarter_night_df


    def _set_data_sleep_quarter_distribution(self, NUM_PARTS, signals_time, \
                                            sleep_stage_events, events):
        """
        Sets up the data by splitting it to show sleep stage distribution

        Parameters
        -----------
        NUM_PARTS : the number of parts of the night to analyse 
        signals_time : Pandas DataFrame
            DataFrame events (columns=['start_time','end_time','channels','name'])
            containing information on the start_time, end_time and name of each signal.
            Used to retrieve which signal came from which file.
        sleep_stage_events   : pandas DataFrame
            List of events from specific stages.
        events  : Pandas DataFrame
            DataFrame events (columns=['group','name','start_sec','duration_sec','channels']) 
            containing a slow wave event

        Returns
        -----------
        quarters : list, 2D list of each individiduals night seperated in NUM_PARTS parts
        """

        # Seperate signals in case there are more than one individual
        signals_seperated = []
        for value in events["name"].unique():
            signals_seperated.append(signals_time[signals_time["name"] == value])


        # If there is no information on the sleep stages, it means all of the data
        # has already been cleaned and is all N2 and N3 only
        if isinstance(sleep_stage_events, str) and sleep_stage_events == '':
            if self.has_one_signal_only:
                s = signals_time.copy()
                s = s.rename(columns={"start_time": "start_sec"}, errors="raise")
                quarters = [np.array_split(s, NUM_PARTS)]
            else:
                quarters = []
                for i in range(len(signals_seperated)):
                    signals_seperated[i] = signals_seperated[i].rename(columns={'start_time':'start_sec'})
                    quarters.append(np.array_split(signals_seperated[i], NUM_PARTS))
       
        # If there are informations on sleep slow waves, only check sleep slow
        # waves detections for N2 and N3
        else:
            if self.has_one_signal_only:
                quarters = sleep_stage_events[sleep_stage_events['name'].isin(['2','3',2,3])]
                quarters = [np.array_split(quarters, NUM_PARTS)]
            else:
                precedent_time = 0
                precedent_index = 0
                quarters = []
                for index, row in sleep_stage_events.iterrows():
                    if row['start_sec'] < precedent_time:
                        sep_sleep_stage = sleep_stage_events[precedent_index : index]
                        stage = sep_sleep_stage[sep_sleep_stage['name'].isin(['2','3',2,3])]
                        quarters.append(np.array_split(stage, NUM_PARTS))
                        precedent_index = index
                    precedent_time = row['start_sec']
                
                # Add last individual
                sep_sleep_stage = sleep_stage_events[precedent_index : index]
                stage = sep_sleep_stage[sep_sleep_stage['name'].isin(['2','3',2,3])]
                quarters.append(np.array_split(stage, NUM_PARTS))
        
        return quarters

    def save_transition_frequency_distribution(self, tfr_data, best_dist, aic_results, output_dir, n_categories):

        # Manual fit
        if len(aic_results)==1:
            self.figure1, self.ax_histo = plt.subplots()
        # Automatic fit
        else:
            self.figure1, self.ax = plt.subplots(2,1)
            self.figure1.set_size_inches(10,10)
            self.ax_histo = self.ax[0]
        
        SlowWaveClassifierResultsView.plot_histogram(self, tfr_data, best_dist)
        try:
            if len(aic_results)==1:
                filename = output_dir+"SW_trans_freq_hist_"+str(n_categories)+"_manual_categories.pdf"
                self.figure1.savefig(filename, bbox_inches='tight')
            else:
                filename = output_dir+"SW_trans_freq_and_AIC_gaussian_fit_"+str(n_categories)+"_auto_categories.pdf"
                self.ax_aic = self.ax[1]
                SlowWaveClassifierResultsView.plot_aic_results(self, aic_results)
                self.figure1.savefig(filename, bbox_inches='tight')
        except :
            error_message = f"Snooz can not write in the file {filename}."+\
                f" Check if the drive is accessible and ensure the file is not already open."
            raise NodeRuntimeException(self.identifier, "SlowWaveClassifier", error_message)  


    def average_slow_waves_char_per_category(self, sw_char_files, n_dist, sw_cohort_df):
        """
        Average slow wave characteristics per category

        Parameters
        -----------
            sw_char_files : list of strings
                List of recording filename.
            n_dist : int
                The number of categories of sleep slow waves to analyse.
            sw_cohort_df : pandas DataFrame
                Slow wave cohort information generated by the slow wave detector.

        Returns
        -----------
            sw_char_cat_cohort : Pandas DataFrame
                Slow wave characteristics averaged for each category
            chan_list_recor : list of list
                List of channels used for the slow wave characteristics for each recording.
        """
        sw_char_cat_cohort = pd.DataFrame()
        chan_list_recor = []
        for i_rec, recor in enumerate(self.slow_wave_list):
            record_avg_all_cat = pd.DataFrame()
            # Split file name from path
            path, filename = os.path.split(sw_char_files[i_rec])
            # Split the extension from the filename
            filename = os.path.splitext(filename)[0]
            # Extract the slow wave characteristics cohort for the current filename
            sw_event_name = sw_cohort_df['sw_event_name'].unique()[0]
            # The filname in the recor has the sw_event_name as suffix
            # Replace the suffix in the filename to get the cohort filename
            filename_cohort = filename.replace('_'+sw_event_name, '')
            recor_cohort = sw_cohort_df[sw_cohort_df['filename']==filename_cohort]

            # Extract channels from the slow wave characteristics dataframe
            channel_list = recor['channels'].unique()
            chan_list_recor.append(channel_list)
            for chan in channel_list:
                recor_chan = recor[recor['channels']==chan]
                recor_cohort_chan = recor_cohort[recor_cohort['chan_label']==chan]
                
                # Average slow wave characteristics for each category
                record_avg_all_cat = pd.DataFrame()
                for i_cat in range(n_dist):
                    cur_char = recor_chan[recor_chan['category']==(i_cat+1)][self.columns_to_avg]
                    record_avg_cat = cur_char.mean()
                    # Add the sw count to the average slow wave characteristics series
                    record_avg_cat['sw_count'] = len(cur_char)
                    # Add the sw density to the average slow wave characteristics series
                    if recor_cohort_chan['total_valid_min'].values[0] == 0:
                        record_avg_cat['sw_density'] = 0
                    else:
                        record_avg_cat['sw_density'] = len(cur_char)/recor_cohort_chan['total_valid_min'].values[0]
                    # Rename the index by adding the prefix f'cat{i_cat+1} to each index
                    record_avg_cat.index = record_avg_cat.index.map(lambda x: f'cat{i_cat+1}_{x}')
                    # Concatenate the average slow wave characteristics series for each category
                    record_avg_all_cat = pd.concat([record_avg_all_cat, record_avg_cat], axis=0)

                # Add a row with the channel label
                record_avg_all_cat.loc['chan_label'] = chan
                # Add a row with the recording time in minute
                record_avg_all_cat.loc['recording_min'] = recor_cohort_chan['recording_min'].values[0]
                # Add a row with the sleep period in minute
                record_avg_all_cat.loc['sleep_period_min'] = recor_cohort_chan['sleep_period_min'].values[0]

                # Convert the pandas series to a dataframe
                record_avg_all_cat = pd.DataFrame(record_avg_all_cat).T
                # Add the filename
                record_avg_all_cat['filename'] = filename_cohort

                # Concatenate the average slow wave characteristics dataframe for each recording
                sw_char_cat_cohort = pd.concat([sw_char_cat_cohort, record_avg_all_cat], axis=0)

        return sw_char_cat_cohort, chan_list_recor


    def average_slow_waves_char_per_cycle(self, sw_char_files, n_dist, sw_cohort_df, chan_list_recor):
        """
        Average slow wave characteristics per category per sleep cycle

        Parameters
        -----------
            sw_char_files : list of strings
                List of recording filename.
            n_dist : int
                The number of categories of sleep slow waves to analyse.
            sw_cohort_df : pandas DataFrame
                Slow wave cohort information generated by the slow wave detector.
            chan_list_recor : list of list
                List of channels used for slow wave characteristics for each recording.

        Returns
        -----------
            sw_char_cat_cohort : Pandas DataFrame
                Slow wave characteristics averaged for each category per sleep cycle
        """

        sw_char_cat_cohort = pd.DataFrame()
        for i_rec, recor in enumerate(self.slow_wave_list):
            record_avg_all_cat = pd.DataFrame()
            # Split file name from path
            path, filename = os.path.split(sw_char_files[i_rec])
            # Split the extension from the filename
            filename = os.path.splitext(filename)[0]
            # Extract the slow wave characteristics cohort for the current filename
            sw_event_name = sw_cohort_df['sw_event_name'].unique()[0]
            # The filname in the recor has the sw_event_name as suffix
            # Replace the suffix in the filename to get the cohort filename
            filename_cohort = filename.replace('_'+sw_event_name, '')
            recor_cohort = sw_cohort_df[sw_cohort_df['filename']==filename_cohort]

            # Extract channels from the slow wave characteristics dataframe
            for chan in chan_list_recor[i_rec]:
                recor_chan = recor[recor['channels']==chan]
                recor_cohort_chan = recor_cohort[recor_cohort['chan_label']==chan]

                # Average slow wave characteristics for each category
                record_avg_all_cat = pd.DataFrame()
                for i_cat in range(n_dist):
                    for i_cycle in range(self.N_CYCLES):
                        # Extract the slow wave characteristics for the current category and cycle
                        cur_char = recor_chan[(recor_chan['category']==(i_cat+1)) & (recor_chan['cycle']==(i_cycle+1))][self.columns_to_avg]
                        record_avg_cat = cur_char.mean()
                        # Add the sw count to the average slow wave characteristics series
                        record_avg_cat['sw_count'] = len(cur_char)
                        # Add the sw density to the average slow wave characteristics series
                        # Check if the key exists
                        if f'cyc{i_cycle+1}_valid_min' not in recor_cohort_chan:
                            raise NodeRuntimeException(self.identifier, "SlowWaveClassifier", \
                                "Set the maximum number of sleep cycles for the slow wave classifier to match the value used for the slow wave detector.")
                        if recor_cohort_chan[f'cyc{i_cycle+1}_valid_min'].values[0] == 0:
                            record_avg_cat['sw_density'] = 0
                        else :
                            record_avg_cat['sw_density'] = len(cur_char)/recor_cohort_chan[f'cyc{i_cycle+1}_valid_min'].values[0]
                        # Rename the index by adding the prefix f'cat{i_cat+1} to each index
                        record_avg_cat.index = record_avg_cat.index.map(lambda x: f'cat{i_cat+1}_cyc{i_cycle+1}_{x}')
                        # Concatenate the average slow wave characteristics series for each category
                        record_avg_all_cat = pd.concat([record_avg_all_cat, record_avg_cat], axis=0)

                # Convert the pandas series to a dataframe
                record_avg_all_cat = pd.DataFrame(record_avg_all_cat).T
                # Concatenate the average slow wave characteristics dataframe for each recording
                sw_char_cat_cohort = pd.concat([sw_char_cat_cohort, record_avg_all_cat], axis=0)

        return sw_char_cat_cohort


    def average_slow_waves_char_per_division(self, sw_char_files, sw_stages_files, n_dist, sw_cohort_df, n_divisions, chan_list_recor):
        """
        Average slow wave characteristics per category per division of night.

        Parameters
        -----------
            sw_char_files : list of strings
                List of characteristics filename.
            sw_stages_files : list of strings
                List of stages filename.
            n_dist : int
                The number of categories of sleep slow waves to analyse.
            sw_cohort_df : pandas DataFrame
                Slow wave cohort information generated by the slow wave detector.
            n_divisions : int
                The number of divisions of the night to analyse.
            chan_list_recor : list of list
                List of channels used for slow wave characteristics for each recording.

        Returns
        -----------
            sw_char_cat_cohort : Pandas DataFrame
                Slow wave characteristics averaged for each category per division of night.
        """


        sw_char_cat_cohort = pd.DataFrame()
        for i_rec, recor in enumerate(self.slow_wave_list):
            record_avg_all_cat = pd.DataFrame()
            # Split file name from path
            path, filename = os.path.split(sw_char_files[i_rec])
            # Split the extension from the filename
            filename = os.path.splitext(filename)[0]
            # Extract the slow wave characteristics cohort for the current filename
            sw_event_name = sw_cohort_df['sw_event_name'].unique()[0]
            # The filname in the recor has the sw_event_name as suffix
            filename_cohort = filename.replace('_'+sw_event_name, '')
            
            # Read the stages file for the current recording
            filename_stages = filename + '_stages' + '.tsv'
            idx_stages = [i for i, x in enumerate(sw_stages_files) if filename_stages in x]
            stages_filename = sw_stages_files[idx_stages[0]]
            recording_stages = pd.read_csv(stages_filename, sep='\t')
            stages_start_sec = recording_stages['start_sec'].values
            stages_stop_sec = stages_start_sec + recording_stages['duration_sec'].values

            # Compute the index number of epochs for each division of the night
            n_epochs_total = len(recording_stages)
            index_div = self.compute_index_division(n_epochs_total, n_divisions)
            
            # Extract the slow wave characteristics from the current channel
            for chan in chan_list_recor[i_rec]:
                recor_chan = recor[recor['channels']==chan]

                # Extract the slow wave characteristics for the current category
                record_avg_all_cat = pd.DataFrame()
                for i_cat in range(n_dist):
                    cur_char = recor_chan[recor_chan['category']==(i_cat+1)]

                    # Extract the slow wave characteristics for the current division
                    for i_div in range(n_divisions):
                        cur_char_div = pd.DataFrame()
                        start_idx, stop_idx = index_div[i_div]
                        starts_sec_idx_div = stages_start_sec[start_idx:stop_idx] # stop_idx is not included
                        stops_sec_idx_div = stages_stop_sec[start_idx:stop_idx]  # stop_idx is not included
                        n_epochs_div = len(starts_sec_idx_div)

                        # For each start and stop time, select the slow wave characteristics
                        for start_sec, stop_sec in zip(starts_sec_idx_div, stops_sec_idx_div):
                            # If the slow wave start in an epoch included in the division, select the slow wave characteristics
                            cur_char_div_temp = cur_char[(cur_char['start_sec']>=start_sec) & (cur_char['start_sec']<stop_sec)]
                            cur_char_div = pd.concat([cur_char_div, cur_char_div_temp], axis=0)

                        # Calculate the average slow wave characteristics
                        record_avg_cat = cur_char_div[self.columns_to_avg].mean()
                        # Add the sw count to the average slow wave characteristics series
                        record_avg_cat['sw_count'] = len(cur_char_div)
                        # Add the sw density to the average slow wave characteristics series
                        if len(starts_sec_idx_div) == 0:
                            record_avg_cat['sw_density'] = 0
                        else :
                            epoch_length_sec = np.unique(stops_sec_idx_div-starts_sec_idx_div)[0]
                            long_div_sec = n_epochs_div*epoch_length_sec
                            record_avg_cat['sw_density'] = len(cur_char_div)/(long_div_sec/60)
                        # Rename the index by adding the prefix f'cat{i_cat+1} to each index
                        record_avg_cat.index = record_avg_cat.index.map(lambda x: f'cat{i_cat+1}_div{i_div+1}_out{n_divisions}_{x}')
                        # Concatenate the average slow wave characteristics series for each category
                        record_avg_all_cat = pd.concat([record_avg_all_cat, record_avg_cat], axis=0)

                # Convert the pandas series to a dataframe
                record_avg_all_cat = pd.DataFrame(record_avg_all_cat).T
                # Concatenate the average slow wave characteristics dataframe for each recording
                sw_char_cat_cohort = pd.concat([sw_char_cat_cohort, record_avg_all_cat], axis=0)

        return sw_char_cat_cohort


    def compute_index_division(self, n_epochs, n_divisions):
        """
        Compute the index number of epochs for each division of the night

        Parameters
        -----------
            n_epochs : int
                The number of epochs in the night.
            n_divisions : int
                The number of divisions of the night to analyse.

        Returns
        -----------
            index_div : list of int
                List of epoch index, one item per division
        """             
        # For dividing a number into (almost) equal whole numbers
        # Remainers are added in the first division first
            # 15 epochs divided by 3 => [5, 5, 5]
            # 14 epochs divided by 3 => [5, 5, 4]
            # 13 epochs divided by 3 => [5, 4, 4]
            # 12 epochs divided by 3 => [4, 4, 4]
        n_epoch_div = [n_epochs // n_divisions + (1 if x < n_epochs % n_divisions else 0)  for x in range (n_divisions)]
        # Create a list of indexes to select the epochs in each division
        # Select the portion of the recording, row integer (NOT label), the end point is excluded with the .iloc
        index_div = []
        index_tmp = 0
        for div in range(n_divisions):
            cur_start = index_tmp
            cur_stop = cur_start+n_epoch_div[div]
            index_div.append([cur_start,cur_stop]) # integer index then last is exclusive
            index_tmp = cur_stop
        return index_div